{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import namedtuple, defaultdict\n",
    "\n",
    "try:\n",
    "    from enum import Enum\n",
    "except ImportError:\n",
    "    # Python 2 doesn't have a builtin Enum type\n",
    "    Enum = object\n",
    "\n",
    "from six import add_metaclass\n",
    "\n",
    "from pyteomics import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrefixSavingMeta(type):\n",
    "    '''A subclass-registering-metaclass that provides easy\n",
    "    lookup of subclasses by prefix attributes.\n",
    "    '''\n",
    "\n",
    "    def __new__(mcs, name, parents, attrs):\n",
    "        new_type = type.__new__(mcs, name, parents, attrs)\n",
    "        prefix = attrs.get(\"prefix_name\")\n",
    "        if prefix:\n",
    "            new_type.prefix_map[prefix.lower()] = new_type\n",
    "        short = attrs.get(\"short_prefix\")\n",
    "        if short:\n",
    "            new_type.prefix_map[short.lower()] = new_type\n",
    "        return new_type\n",
    "    \n",
    "    def find_by_tag(self, tag_name):\n",
    "        if tag_name is None:\n",
    "            raise ValueError(\"tag_name cannot be None!\")\n",
    "        tag_name = tag_name.lower()\n",
    "        return self.prefix_map[tag_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TagTypeEnum(Enum):\n",
    "    unimod = 0\n",
    "    psimod = 1\n",
    "    massmod = 2\n",
    "    generic = 3\n",
    "    info = 4\n",
    "    gnome = 5\n",
    "    xlmod = 6\n",
    "\n",
    "    formula = 7\n",
    "    glycan = 8\n",
    "\n",
    "    localization_marker = 9\n",
    "    position_label = 10\n",
    "    group_placeholder = 999\n",
    "\n",
    "\n",
    "_sentinel = object()\n",
    "\n",
    "\n",
    "@add_metaclass(PrefixSavingMeta)\n",
    "class TagBase(object):\n",
    "    '''A base class for all tag types.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    type: Enum\n",
    "        An element of :class:`TagTypeEnum` saying what kind of tag this is.\n",
    "    value: object\n",
    "        The data stored in this tag, usually an externally controlled name\n",
    "    extra: list\n",
    "        Any extra tags that were nested within this tag. Usually limited to INFO\n",
    "        tags but may be other synonymous controlled vocabulary terms.\n",
    "    group_id: str or None\n",
    "        A short label denoting which group, if any, this tag belongs to\n",
    "    '''\n",
    "    __slots__ = (\"type\", \"value\", \"extra\", \"group_id\")\n",
    "\n",
    "    prefix_name = None\n",
    "    short_prefix = None\n",
    "    prefix_map = {}\n",
    "    \n",
    "    def __init__(self, type, value, extra=None, group_id=None):\n",
    "        self.type = type\n",
    "        self.value = value\n",
    "        self.extra = extra\n",
    "        self.group_id = group_id\n",
    "\n",
    "    def __str__(self):\n",
    "        part = self._format_main()\n",
    "        if self.extra:\n",
    "            rest = [str(e) for e in self.extra]\n",
    "            label = '|'.join([part] + rest)\n",
    "        else:\n",
    "            label = part\n",
    "        if self.group_id:\n",
    "            label = '%s%s' % (label, self.group_id)\n",
    "        return '%s' % label\n",
    "    \n",
    "    def __repr__(self):\n",
    "        template = \"{self.__class__.__name__}({self.value!r}, {self.extra!r}, {self.group_id!r})\"\n",
    "        return template.format(self=self)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if other is None:\n",
    "            return False\n",
    "        return (self.type == other.type) and (self.value == other.value) and (self.extra == other.extra) \\\n",
    "            and (self.group_id == other.group_id)\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return not self == other\n",
    "\n",
    "    def find_extra(self, label):\n",
    "        out = []\n",
    "        if not self.extra:\n",
    "            return out\n",
    "        for e in self.extra:\n",
    "            if e.type == label:\n",
    "                out.append(e)\n",
    "        return out\n",
    "\n",
    "\n",
    "class PositionLabelTag(TagBase):\n",
    "    '''A tag to mark that a position is involved in a group in some way, but does\n",
    "    not imply any specific semantics.\n",
    "    '''\n",
    "    __slots__ = ()\n",
    "\n",
    "    def __init__(self, value=None, extra=None, group_id=None):\n",
    "        assert group_id is not None\n",
    "        super(PositionLabelTag, self).__init__(TagTypeEnum.position_label, group_id, extra, group_id)\n",
    "    \n",
    "    def _format_main(self):\n",
    "        return \"#{self.group_id}\".format(self=self)\n",
    "\n",
    "\n",
    "class LocalizationMarker(TagBase):\n",
    "    '''A tag to mark a particular localization site \n",
    "    '''\n",
    "    __slots__ = ()\n",
    "    \n",
    "    def __init__(self, value, extra=None, group_id=None):\n",
    "        assert group_id is not None\n",
    "        super(LocalizationMarker, self).__init__(TagTypeEnum.localization_marker, float(value), extra, group_id)\n",
    "    \n",
    "    def _format_main(self):\n",
    "        return \"#{self.group_id}({self.value!f})\".format(self=self)\n",
    "\n",
    "\n",
    "class InformationTag(TagBase):\n",
    "    '''A tag carrying free text describing the location\n",
    "    '''\n",
    "    __slots__ = ()\n",
    "\n",
    "    prefix_name = \"INFO\"\n",
    "\n",
    "    def __init__(self, value, extra=None, group_id=None):\n",
    "        super(InformationTag, self).__init__(TagTypeEnum.info, str(value), extra, group_id)\n",
    "\n",
    "    def _format_main(self):\n",
    "        return str(self.value)\n",
    "\n",
    "\n",
    "class MassModification(TagBase):\n",
    "    '''A modification defined purely by a signed mass shift in Daltons.\n",
    "\n",
    "    The value of a :class:`MassModification` is always a :class:`float`\n",
    "    '''\n",
    "    __slots__ = ()\n",
    "    \n",
    "    def __init__(self, value, extra=None, group_id=None):\n",
    "        super(MassModification, self).__init__(TagTypeEnum.massmod, float(value), extra, group_id)\n",
    "    \n",
    "    def _format_main(self):\n",
    "        return '%0.4f' % self.value\n",
    "\n",
    "\n",
    "    \n",
    "class ModificationBase(TagBase):\n",
    "    '''A base class for all modification tags with marked prefixes.\n",
    "    '''\n",
    "\n",
    "    _tag_type = None\n",
    "    __slots__ = ()\n",
    "    \n",
    "    def __init__(self, value, extra=None, group_id=None):\n",
    "        super(ModificationBase, self).__init__(\n",
    "            self._tag_type, value, extra, group_id)\n",
    "\n",
    "    def _format_main(self):\n",
    "        return \"{self.prefix_name}:{self.value}\".format(self=self)\n",
    "    \n",
    "    def resolve(self):\n",
    "        '''Find the term and return it's properties\n",
    "        '''\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class FormulaModification(ModificationBase):\n",
    "    prefix_name = \"Formula\"\n",
    "\n",
    "    _tag_type = TagTypeEnum.formula\n",
    "\n",
    "    def resolve(self):\n",
    "        # The handling of fixed isotopes is wrong here as Pyteomics uses a different\n",
    "        # convention.\n",
    "        from pyteomics.mass import Composition\n",
    "        composition = Composition(formula=''.join(self.value.split(\" \")))\n",
    "        return {\n",
    "            \"mass\": composition.mass(),\n",
    "            \"composition\": composition\n",
    "        }\n",
    "\n",
    "\n",
    "class GlycanModification(ModificationBase):\n",
    "    prefix_name = \"Glycan\"\n",
    "\n",
    "    _tag_type = TagTypeEnum.glycan\n",
    "\n",
    "    \n",
    "class GenericModification(TagBase):\n",
    "    __slots__ = ()\n",
    "    \n",
    "    def __init__(self, value, extra=None, group_id=None):\n",
    "        super(GenericModification, self).__init__(TagTypeEnum.generic, value, extra, group_id)\n",
    "    \n",
    "    def _format_main(self):\n",
    "        return self.value\n",
    "\n",
    "    def resolve(self):\n",
    "        '''Find the term, searching through all available vocabularies and\n",
    "        return the first match's properties\n",
    "        '''\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class UnimodModification(ModificationBase):\n",
    "    __slots__ = ()\n",
    "    \n",
    "    prefix_name = \"UNIMOD\"\n",
    "    short_prefix = \"U\"\n",
    "    _tag_type = TagTypeEnum.unimod\n",
    "\n",
    "\n",
    "class PSIModModification(ModificationBase):\n",
    "    __slots__ = ()\n",
    "    \n",
    "    prefix_name = \"MOD\"\n",
    "    short_prefix = 'M'\n",
    "    _tag_type = TagTypeEnum.psimod\n",
    "\n",
    "\n",
    "class GNOmeModification(ModificationBase):\n",
    "    __slots__ = ()\n",
    "    \n",
    "    prefix_name = \"GNO\"\n",
    "    # short_prefix = 'G'\n",
    "    _tag_type = TagTypeEnum.gnome\n",
    "\n",
    "    \n",
    "class XLMODModification(ModificationBase):\n",
    "    __slots__ = ()\n",
    "    \n",
    "    prefix_name = \"XLMOD\"\n",
    "    # short_prefix = 'XL'\n",
    "    _tag_type = TagTypeEnum.xlmod\n",
    "\n",
    "\n",
    "def split_tags(tokens):\n",
    "    '''Split a token array into discrete sets of tag\n",
    "    tokens.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tokens: list\n",
    "        The characters of the tag token buffer\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list of list:\n",
    "        The tokens for each contained tag\n",
    "    '''\n",
    "    starts = [0]\n",
    "    ends = []\n",
    "    for i, c in enumerate(tokens):\n",
    "        if c == '|':\n",
    "            ends.append(i)\n",
    "            starts.append(i + 1)\n",
    "        elif (i != 0 and c == '#'):\n",
    "            ends.append(i)\n",
    "            starts.append(i)\n",
    "    ends.append(len(tokens))\n",
    "    out = []\n",
    "    for i, start in enumerate(starts):\n",
    "        end = ends[i]\n",
    "        out.append(tokens[start:end])\n",
    "    return out\n",
    "\n",
    "\n",
    "def find_prefix(tokens):\n",
    "    '''Find the prefix, if any of the tag defined by `tokens`\n",
    "    delimited by \":\".\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tokens: list\n",
    "        The tag tokens to search\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    prefix: str or None\n",
    "        The prefix string, if found\n",
    "    rest: str\n",
    "        The rest of the tokens, merged as a string\n",
    "    '''\n",
    "    for i, c in enumerate(tokens):\n",
    "        if c == ':':\n",
    "            return ''.join(tokens[:i]), ''.join(tokens[i + 1:])\n",
    "    return None, tokens\n",
    "\n",
    "def process_marker(tokens):\n",
    "    '''Process a marker, which is a tag whose value starts with #.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tokens: list\n",
    "        The tag tokens to parse\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    PositionLabelTag or LocalizationMarker\n",
    "    '''\n",
    "    if tokens[1:3] == 'XL':\n",
    "        return PositionLabelTag(None, group_id=''.join(tokens))\n",
    "    else:\n",
    "        group_id = None\n",
    "        value = None\n",
    "        for i, c in  enumerate(tokens):\n",
    "            if c == '(':\n",
    "                group_id = ''.join(tokens[:i])\n",
    "                if tokens[-1] != ')':\n",
    "                    raise Exception(\"Localization marker with score missing closing parenthesis\")\n",
    "                value = float(''.join(tokens[i + 1:-1]))\n",
    "                return LocalizationMarker(value, group_id=group_id)\n",
    "        else:\n",
    "            group_id = ''.join(tokens)\n",
    "            return PositionLabelTag(group_id=group_id)\n",
    "        \n",
    "\n",
    "\n",
    "def process_tag_tokens(tokens):\n",
    "    '''Convert a tag token buffer into a parsed :class:`TagBase` instance\n",
    "    of the appropriate sub-type with zero or more sub-tags.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tokens: list\n",
    "        The tokens to parse\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    TagBase:\n",
    "        The parsed tag\n",
    "    '''\n",
    "    parts = split_tags(tokens)\n",
    "    main_tag = parts[0]\n",
    "    if main_tag[0] in ('+', '-'):\n",
    "        main_tag = ''.join(main_tag)\n",
    "        main_tag = MassModification(main_tag)\n",
    "    elif main_tag[0] == '#':\n",
    "        main_tag = process_marker(main_tag)\n",
    "    else:\n",
    "        prefix, value = find_prefix(main_tag)\n",
    "        if prefix is None:\n",
    "            main_tag = GenericModification(''.join(value))\n",
    "        else:\n",
    "            tag_type = TagBase.find_by_tag(prefix)\n",
    "            main_tag = tag_type(value)\n",
    "    if len(parts) > 1:\n",
    "        extras = []\n",
    "        for part in parts[1:]:\n",
    "            prefix, value = find_prefix(part)\n",
    "            if prefix is None:\n",
    "                if value[0] == \"#\":\n",
    "                    marker = process_marker(value)\n",
    "                    if isinstance(marker, PositionLabelTag):\n",
    "                        main_tag.group_id = ''.join(value)\n",
    "                    else:\n",
    "                        main_tag.group_id = marker.group_id\n",
    "                        extras.append(marker)\n",
    "                else:\n",
    "                    extras.append(GenericModification(''.join(value)))\n",
    "            else:\n",
    "                tag_type = TagBase.find_by_tag(prefix)\n",
    "                extras.append(tag_type(value))\n",
    "        main_tag.extra = extras\n",
    "    return main_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModificationRule(object):\n",
    "    '''Define a fixed modification rule which dictates a modification tag is\n",
    "    always applied at one or more amino acid residues.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    modification_tag: TagBase\n",
    "        The modification to apply\n",
    "    targets: list\n",
    "        The list of amino acids this applies to\n",
    "    '''\n",
    "    __slots__ = ('modification_tag', 'targets')\n",
    "\n",
    "    def __init__(self, modification_tag, targets=None):\n",
    "        self.modification_tag = modification_tag\n",
    "        self.targets = targets\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if other is None:\n",
    "            return False\n",
    "        return self.modification_tag == other.modification_tag and self.targets == other.targets\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return not self == other\n",
    "\n",
    "    def __str__(self):\n",
    "        targets = ','.join(self.targets)\n",
    "        return \"<{self.modification_tag}@{targets}>\".format(self=self, targets=targets)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"{self.__class__.__name__}({self.modification_tag!r}, {self.targets})\".format(self=self)\n",
    "\n",
    "\n",
    "class StableIsotope(object):\n",
    "    '''Define a fixed isotope that is applied globally to all amino acids.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    isotope: str\n",
    "        The stable isotope string, of the form [<isotope-number>]<element> or a special\n",
    "        isotopoform's name.\n",
    "    '''\n",
    "    __slots__ = ('isotope', )\n",
    "\n",
    "    def __init__(self, isotope):\n",
    "        self.isotope = isotope\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if other is None:\n",
    "            return False\n",
    "        return self.isotope == other.isotope\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return not self == other\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<{self.isotope}>\".format(self=self)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"{self.__class__.__name__}({self.isotope})\".format(self=self)\n",
    "\n",
    "\n",
    "class TaggedInterval(object):\n",
    "    '''Define a fixed interval over the associated sequence which contains the localization\n",
    "    of the associated tag.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    start: int\n",
    "        The starting position (inclusive) of the interval along the primary sequence\n",
    "    end: int\n",
    "        The ending position (exclusive) of the interval along the primary sequence\n",
    "    tag: TagBase\n",
    "        The tag being localized\n",
    "    '''\n",
    "    __slots__ = ('start', 'end', 'tag')\n",
    "\n",
    "    def __init__(self, start, end=None, tag=None):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.tag = tag\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if other is None:\n",
    "            return False\n",
    "        return self.start == other.start and self.end == other.end and self.tag == other.tag\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return not self == other\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"({self.start}-{self.end}){self.tag!r}\".format(self=self)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"{self.__class__.__name__}({self.start}, {self.end}, {self.tag})\".format(self=self)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TagParser(object):\n",
    "    '''A parser which accumulates tokens until it is asked to parse them into\n",
    "    :class:`TagBase` instances.\n",
    "\n",
    "    Implements a subset of the Sequence protocol.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    buffer: list\n",
    "        The list of tokens accumulated since the last parsing.\n",
    "    group_ids: set\n",
    "        The set of all group IDs that have been produced so far.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, initial=None, group_ids=None):\n",
    "        if initial:\n",
    "            self.buffer = list(initial)\n",
    "        else:\n",
    "            self.buffer = []\n",
    "        if group_ids:\n",
    "            self.group_ids = set(group_ids)\n",
    "        else:\n",
    "            self.group_ids = set()\n",
    "    \n",
    "    def append(self, c):\n",
    "        '''Append a new character to the buffer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        c: str\n",
    "            The character appended\n",
    "        '''\n",
    "        self.buffer.append(c)\n",
    "    \n",
    "    def reset(self):\n",
    "        '''Discard the content of the current buffer.\n",
    "        '''\n",
    "        self.buffer = []\n",
    "    \n",
    "    def __bool__(self):\n",
    "        return bool(self.buffer)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter(self.buffer)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.buffer[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def process(self):\n",
    "        '''Parse the content of the internal buffer, clear the buffer,\n",
    "        and return the parsed tag.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        TagBase\n",
    "        '''\n",
    "        tag = process_tag_tokens(self.buffer)\n",
    "        if tag.group_id:\n",
    "            self.group_ids.add(tag.group_id)\n",
    "        self.reset()\n",
    "        return tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParserStateEnum(Enum):\n",
    "    before_sequence = 0\n",
    "    tag_before_sequence = 1\n",
    "    global_tag = 2\n",
    "    fixed_spec = 3\n",
    "    labile_tag = 4\n",
    "    sequence = 5\n",
    "    tag_in_sequence = 6\n",
    "    interval_tag = 7\n",
    "    tag_after_sequence = 8\n",
    "    stable_isotope = 9\n",
    "\n",
    "    done = 999\n",
    "\n",
    "\n",
    "BEFORE = ParserStateEnum.before_sequence\n",
    "TAG_BEFORE = ParserStateEnum.tag_before_sequence\n",
    "FIXED = ParserStateEnum.fixed_spec\n",
    "GLOBAL = ParserStateEnum.global_tag\n",
    "ISOTOPE = ParserStateEnum.stable_isotope\n",
    "LABILE = ParserStateEnum.labile_tag\n",
    "SEQ = ParserStateEnum.sequence\n",
    "TAG = ParserStateEnum.tag_in_sequence\n",
    "INTERVAL_TAG = ParserStateEnum.interval_tag\n",
    "TAG_AFTER = ParserStateEnum.tag_after_sequence\n",
    "DONE = ParserStateEnum.done\n",
    "\n",
    "VALID_AA = set(\"QWERTYIPASDFGHKLCVNM\")\n",
    "\n",
    "def parse_proforma(sequence):\n",
    "    '''Tokenize a ProForma sequence into a sequence of amino acid+tag positions, and a\n",
    "    mapping of sequence-spanning modifiers.\n",
    "\n",
    "    .. note::\n",
    "        This is a state machine parser, but with certain sub-state paths\n",
    "        unrolled to avoid an explosion of formal intermediary states.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sequence: str\n",
    "        The sequence to parse\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    parsed_sequence: list\n",
    "        The (amino acid: str, TagBase or None) pairs denoting the positions along the primary sequence\n",
    "    modifiers: dict\n",
    "        A mapping listing the labile modifications, fixed modifications, stable isotopes, unlocalized\n",
    "        modifications, tagged intervals, and group IDs\n",
    "    '''\n",
    "    labile_modifications = []\n",
    "    fixed_modifications = []\n",
    "    unlocalized_modifications = []\n",
    "    intervals = []\n",
    "    isotopes = []\n",
    "    \n",
    "    n_term = None\n",
    "    c_term = None\n",
    "    \n",
    "    i = 0\n",
    "    n = len(sequence)\n",
    "    \n",
    "    positions = []\n",
    "    state = BEFORE\n",
    "    depth = 0\n",
    "    \n",
    "    current_aa = None\n",
    "    current_tag = TagParser()\n",
    "    current_interval = None\n",
    "    \n",
    "    while i < n:\n",
    "        c = sequence[i]\n",
    "        i += 1\n",
    "        if state == BEFORE:\n",
    "            if c == '[':\n",
    "                state = TAG_BEFORE\n",
    "                depth = 1\n",
    "            elif c == '{':\n",
    "                state = LABILE\n",
    "                depth = 1\n",
    "            elif c == '<':\n",
    "                state = FIXED\n",
    "            elif c in VALID_AA:\n",
    "                current_aa = c\n",
    "                state = SEQ\n",
    "            else:\n",
    "                raise Exception(\"Error In State {state}, unexpected {c} found at index {i}\".format(**locals()))\n",
    "        elif state == SEQ:\n",
    "            if c in VALID_AA:\n",
    "                positions.append((current_aa, current_tag.process() if current_tag else None))\n",
    "                current_aa = c\n",
    "            elif c == '[':\n",
    "                state = TAG\n",
    "                depth = 1\n",
    "            elif c == '(':\n",
    "                current_interval = TaggedInterval(len(positions) + 1)\n",
    "            elif c == ')':\n",
    "                if current_interval is None:\n",
    "                    raise Exception(\"Error In State {state}, unexpected {c} found at index {i}\".format(**locals()))\n",
    "                else:\n",
    "                    current_interval.end = len(positions) + 1\n",
    "                    if i >= n or sequence[i] != '[':\n",
    "                        raise Exception(\"Missing Interval Tag\")\n",
    "                    i += 1\n",
    "                    depth = 1\n",
    "                    state = INTERVAL_TAG\n",
    "            elif c == '-':\n",
    "                state = TAG_AFTER\n",
    "                if i >= n or sequence[i] != '[':\n",
    "                    raise Exception(\"Missing Interval Tag\")\n",
    "                i += 1\n",
    "                depth = 1                \n",
    "            else:\n",
    "                raise Exception(\"Error In State {state}, unexpected {c} found at index {i}\".format(**locals()))\n",
    "        elif state == TAG or state == TAG_BEFORE or state == TAG_AFTER or state == GLOBAL:\n",
    "            if c == '[':\n",
    "                depth += 1\n",
    "            elif c == ']':\n",
    "                depth -= 1\n",
    "                if depth <= 0:\n",
    "                    depth = 0\n",
    "                    if state == TAG: \n",
    "                        state = SEQ\n",
    "                    elif state == TAG_BEFORE:\n",
    "                        if i < n:\n",
    "                            cnext = sequence[i]\n",
    "                            if cnext == '?':\n",
    "                                unlocalized_modifications.append(current_tag.process())\n",
    "                                i += 1\n",
    "                            elif cnext == '-':\n",
    "                                n_term = current_tag.process()\n",
    "                                i += 1\n",
    "                            else:\n",
    "                                i += 1\n",
    "                                raise Exception(\"Error In State {state}, unexpected {cnext} found at index {i}\".format(**locals()))\n",
    "\n",
    "                        state = BEFORE\n",
    "                    elif state == TAG_AFTER:\n",
    "                        c_term = current_tag.process()\n",
    "                        state = DONE\n",
    "                    elif state == GLOBAL:\n",
    "                        # Gobble the rest of the global tag inline to avoid spawning\n",
    "                        # a whole new state.\n",
    "                        if i < n:\n",
    "                            c = sequence[i]\n",
    "                            i += 1\n",
    "                            if c != '@':\n",
    "                                raise Exception(\n",
    "                                    (\"Error In State {state}, fixed modification detected without \"\n",
    "                                    \"target amino acids found at index {i}\").format(**locals()))\n",
    "                            end = 0\n",
    "                            targets = []\n",
    "                            while i < n:\n",
    "                                c = sequence[i]\n",
    "                                i += 1\n",
    "                                if c in VALID_AA:\n",
    "                                    targets.append(c)\n",
    "                                elif c == ',':\n",
    "                                    pass\n",
    "                                elif '>':\n",
    "                                    break\n",
    "                            else:\n",
    "                                raise Exception(\n",
    "                                    (\"Error In State {state}, unclosed fixed modification rule\").format(**locals()))\n",
    "\n",
    "                        fixed_modifications.append(\n",
    "                            ModificationRule(current_tag.process(), targets))\n",
    "                        state = BEFORE\n",
    "            else:\n",
    "                current_tag.append(c)\n",
    "        elif state == FIXED:\n",
    "            if c == '[':\n",
    "                state = GLOBAL\n",
    "            else:\n",
    "                state = ISOTOPE\n",
    "                current_tag.append(c)\n",
    "        elif state == ISOTOPE:\n",
    "            if c != '>':\n",
    "                current_tag.append(c)\n",
    "            else:\n",
    "                isotopes.append(StableIsotope(''.join(current_tag)))\n",
    "                current_tag.reset()\n",
    "                state = BEFORE\n",
    "        elif state == LABILE:\n",
    "            if c == '{':\n",
    "                depth += 1\n",
    "            elif c == '}':\n",
    "                depth -= 1\n",
    "                if depth <= 0:\n",
    "                    depth = 0\n",
    "                    labile_modifications.append(current_tag.process())\n",
    "                    state = BEFORE\n",
    "            else:\n",
    "                current_tag.append(c)\n",
    "        elif state == INTERVAL_TAG:\n",
    "            if c == '[':\n",
    "                depth += 1\n",
    "            elif c == ']':\n",
    "                depth -= 1\n",
    "                if depth <= 0:\n",
    "                    depth = 0\n",
    "                    current_interval.tag = current_tag.process()\n",
    "                    intervals.append(current_interval)\n",
    "                    current_interval = None\n",
    "                    state = SEQ\n",
    "            else:\n",
    "                current_tag.append(c)\n",
    "        else:\n",
    "            raise Exception(\"Error In State {state}, unexpected {c} found at index {i}\".format(**locals()))\n",
    "    if state in (ISOTOPE, TAG, TAG_AFTER, TAG_BEFORE, LABILE, ):\n",
    "        raise Exception(\"Error In State {state}, unclosed group reached end of string!\".format(**locals()))\n",
    "    if current_aa:\n",
    "        positions.append((current_aa, current_tag.process() if current_tag else None))\n",
    "    return positions, {\n",
    "        'n_term': n_term,\n",
    "        'c_term': c_term,\n",
    "        'unlocalized_modifications': unlocalized_modifications,\n",
    "        'labile_modifications': labile_modifications,\n",
    "        'fixed_modifications': fixed_modifications,\n",
    "        'intervals': intervals,\n",
    "        'isotopes': isotopes,\n",
    "        'group_ids': list(current_tag.group_ids)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "([('S', None),\n",
       "  ('T', UnimodModification('Ox', None, None)),\n",
       "  ('E', None),\n",
       "  ('P', None),\n",
       "  ('P', None),\n",
       "  ('I', None),\n",
       "  ('N', None),\n",
       "  ('G', None)],\n",
       " {'n_term': GenericModification('Hex', None, None),\n",
       "  'c_term': None,\n",
       "  'unlocalized_modifications': [GenericModification('Bar', None, None)],\n",
       "  'labile_modifications': [GenericModification('Foo', None, None)],\n",
       "  'fixed_modifications': [ModificationRule(GenericModification('Carbamidomethyl', None, None), ['C'])],\n",
       "  'intervals': [TaggedInterval(2, 5, 18.0000)],\n",
       "  'isotopes': [StableIsotope(13C)],\n",
       "  'group_ids': []})"
      ]
     },
     "metadata": {},
     "execution_count": 231
    }
   ],
   "source": [
    "seq, fields = tokenize_proforma(\"<[Carbamidomethyl]@C><13C>[Bar]?{Foo}[Hex]-ST[U:Ox](EPP)[+18]ING\")\n",
    "seq, fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "([('S', None),\n",
       "  ('E', None),\n",
       "  ('P', None),\n",
       "  ('P', None),\n",
       "  ('I', None),\n",
       "  ('N', None),\n",
       "  ('G', None)],\n",
       " {'n_term': None,\n",
       "  'c_term': None,\n",
       "  'unlocalized_modifications': [],\n",
       "  'labile_modifications': [],\n",
       "  'fixed_modifications': [],\n",
       "  'intervals': [TaggedInterval(1, 4, 18.0000)],\n",
       "  'isotopes': [],\n",
       "  'group_ids': []})"
      ]
     },
     "metadata": {},
     "execution_count": 232
    }
   ],
   "source": [
    "seq, fields = tokenize_proforma(\"S(EPP)[+18]ING\")\n",
    "seq, fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "([('E', None),\n",
       "  ('M', GenericModification('Oxidation', None, None)),\n",
       "  ('E', None),\n",
       "  ('V', None),\n",
       "  ('T', LocalizationMarker(0.01, None, '#s1')),\n",
       "  ('S', LocalizationMarker(0.09, None, '#s1')),\n",
       "  ('E', None),\n",
       "  ('S', LocalizationMarker(0.9, None, '#s1')),\n",
       "  ('P', None),\n",
       "  ('E', None),\n",
       "  ('K', None)],\n",
       " {'n_term': None,\n",
       "  'c_term': None,\n",
       "  'unlocalized_modifications': [GenericModification('Phospho', [], '#s1')],\n",
       "  'labile_modifications': [],\n",
       "  'fixed_modifications': [],\n",
       "  'intervals': [],\n",
       "  'isotopes': [],\n",
       "  'group_ids': ['#s1']})"
      ]
     },
     "metadata": {},
     "execution_count": 233
    }
   ],
   "source": [
    "parse_proforma(\"[Phospho#s1]?EM[Oxidation]EVT[#s1(0.01)]S[#s1(0.09)]ES[#s1(0.90)]PEK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "([('E', None),\n",
       "  ('M', GenericModification('Oxidation', None, None)),\n",
       "  ('E', None),\n",
       "  ('V', None),\n",
       "  ('T', LocalizationMarker(0.01, None, '#g1')),\n",
       "  ('S', LocalizationMarker(0.09, None, '#g1')),\n",
       "  ('E', None),\n",
       "  ('S',\n",
       "   GenericModification('Phospho', [LocalizationMarker(0.9, None, '#g1')], '#g1')),\n",
       "  ('P', None),\n",
       "  ('E', None),\n",
       "  ('K', None)],\n",
       " {'n_term': None,\n",
       "  'c_term': None,\n",
       "  'unlocalized_modifications': [],\n",
       "  'labile_modifications': [],\n",
       "  'fixed_modifications': [],\n",
       "  'intervals': [],\n",
       "  'isotopes': [],\n",
       "  'group_ids': ['#g1']})"
      ]
     },
     "metadata": {},
     "execution_count": 234
    }
   ],
   "source": [
    "tokenize_proforma(\"EM[Oxidation]EVT[#g1(0.01)]S[#g1(0.09)]ES[Phospho#g1(0.90)]PEK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "([('E', None),\n",
       "  ('M', None),\n",
       "  ('E', None),\n",
       "  ('V', None),\n",
       "  ('T', LocalizationMarker(0.01, None, '#g1')),\n",
       "  ('S', LocalizationMarker(0.09, None, '#g1')),\n",
       "  ('E', None),\n",
       "  ('S',\n",
       "   GlycanModification('HexNAc 1', [LocalizationMarker(0.9, None, '#g1')], '#g1')),\n",
       "  ('P', None),\n",
       "  ('E', None),\n",
       "  ('K', None)],\n",
       " {'n_term': None,\n",
       "  'c_term': None,\n",
       "  'unlocalized_modifications': [],\n",
       "  'labile_modifications': [],\n",
       "  'fixed_modifications': [],\n",
       "  'intervals': [],\n",
       "  'isotopes': [],\n",
       "  'group_ids': ['#g1']})"
      ]
     },
     "metadata": {},
     "execution_count": 235
    }
   ],
   "source": [
    "tokenize_proforma(\"EMEVT[#g1(0.01)]S[#g1(0.09)]ES[Glycan:HexNAc 1#g1(0.90)]PEK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}